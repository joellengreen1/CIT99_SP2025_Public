{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "419043bd",
   "metadata": {},
   "source": [
    "# Week 06 - Classification Models Logistic Regression\n",
    "The goal of this assignment is to introduce students to classification models, helping them understand how to apply machine learning algorithms to predict categories. Students will work with two datasets and will use a variety of classification models to compare their performance. The assignment will focus on using **Logistic Regression** in this Jupyter Notebook.\n",
    "<br><br>\n",
    "The libraries that you will use are listed in the code cell below. Please run the code cell. See the Getting Started module in the Canvas Classroom to see the parameter options available to each class and method used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca7a6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730cc29c",
   "metadata": {},
   "source": [
    "# Reading in the Data set\n",
    " You will use the Titanic data set to predict whether a person survives based on data from the data set.  The code beloow reads data into the a dataframe from a dataset located on the Internet.\n",
    "\n",
    "```\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "```\n",
    "To see the parameters of pd.read_csv click this url: https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "\n",
    "# Question 1\n",
    "1. Read the titanic data set into a dataframe variable called titanic.\n",
    "2. Display the first 5 records in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3d5b7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe42b009",
   "metadata": {},
   "source": [
    "# Data Structure and Summary Statistics\n",
    "Create a data structure list and also the summary statistics using the info(), describe().T, describe(include=['object']).T methods.\n",
    "\n",
    "- info() parameters: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html#pandas.DataFrame.info\n",
    "- describe() parameters: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html#pandas.DataFrame.describe\n",
    "\n",
    "\n",
    "\n",
    "# Question 2\n",
    "1. Use the appropriate dataframe variable and list the data structure using info() method.\n",
    "2. Use the appropriate dataframe variable and list the data structure using describe().T for the numerical values.\n",
    "3. Use the appropriate dataframe varible and list the data structure using describe(include=['object']).T for the string variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adbc504f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2 - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a44b8695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2 - 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "467f2d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2 - 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5c3ed3",
   "metadata": {},
   "source": [
    "# Drop variables that will not be used in the model\n",
    "Some variables are not relevant to the model such as PassengerId, Name, and Ticket.  Cabin would be valuable if we knew if the missing values indicated no cabin.  But since we cannot make that assumption that missing data indicated passenger did not have a cabin.  We will delete the Cabin column.  Also there is a lot of missing data.\n",
    "\n",
    "- drop parameters: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html#pandas.DataFrame.drop\n",
    "- dl = ['column1', 'column2', 'column3']  # list all the columns you want to drop in a list\n",
    "- df.drop(columns=dl, axis=1, inplace=True)\n",
    "\n",
    "# Question 3\n",
    "1. Create a list of the column names you want to drop.  Run drop only once if you run twice it will generate an error.\n",
    "2. Using the drop method to drop the columns above from the titanic dataframe.  Put all code in one code cell.\n",
    "3. Use info() method to display remaining columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "028ed6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc2e9f7",
   "metadata": {},
   "source": [
    "# Determine balanced data\n",
    "Is the data balanced?  Is the target variable equal in each output value?  \n",
    "\n",
    "- df['column'].value_counts\n",
    "- value_counts method parameters: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html#pandas.DataFrame.value_counts \n",
    "\n",
    "# Question 4\n",
    "1. Use the value_counts() method to determine if the target variable, Survived has equal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11c03930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e441ae",
   "metadata": {},
   "source": [
    "# Splitting the dataset\n",
    "It is time to split the dataset into training and testing data sets.  Since the Survived column is not equal we will use a stratified random sample based on the Survived column.\n",
    "\n",
    "- train_test_split parameters: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "- train, test = train_test_split(df, test_size=0.2, random_state=33, stratify=df['target column'])\n",
    "\n",
    "# Question 5\n",
    "1. Split the data into train and test dataframes using the train_test_split function.\n",
    "2. Split the data 70% in training and 30% in testing.\n",
    "3. Use the random_state = 42. (seed for random number generator)\n",
    "4. Stratified the data by the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdc33dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d0dff3",
   "metadata": {},
   "source": [
    "# View the percentage in training and test set\n",
    "We stratified the sample based on the target variable.  We can see the results of the target variables in the test and training set by using the value_counts(normalize=True).\n",
    "\n",
    "```\n",
    "y.value_counts(normalize=True) # to get percentage in each number in Survived for test set\n",
    "y_t.value_counts(normalize=True) # to get percentage in each number in Survived for test set\n",
    "```\n",
    "# Question 6\n",
    "1. Determine the percentage for the target variable for the entire data set.\n",
    "2. Determine the percentage for the target variable in the training data set.\n",
    "3. Determine the percentage for the target variable in the testing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f571617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 6 - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5642ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 6 - 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03feef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 6 - 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46ec587",
   "metadata": {},
   "source": [
    "# Correlation of training data set\n",
    "Create a correlation matrix of the training data set using the corr() method\n",
    "- the corr() parameters is at this url: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html#pandas.DataFrame.corr\n",
    "\n",
    "```\n",
    "df_t.corr(numeric_only=True)\n",
    "```\n",
    "\n",
    "# Question 7\n",
    "1. Using the corr() method and numeric_only=True as the parameter along with the appropriate dataframe to fine the correlation matrix of the training data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f61f63d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1c567b",
   "metadata": {},
   "source": [
    "# Data Visualization\n",
    "We will create a bar chart of the sex and # survived by sex.  Also, the Embared and the number serviced.  In Week 04 you learned to create a bar chart using code below.\n",
    "\n",
    "- groupby parameters: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html#pandas.DataFrame.groupby\n",
    "- dataframe bar plot parameters: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.bar.html#pandas.DataFrame.plot.bar\n",
    "\n",
    "```\n",
    "dfg=train.groupby(\"x column\", as_index=False)[\"target column\"].sum()\n",
    "dfg.plot.bar(x='x column', y='y column', rot=0)\n",
    "```\n",
    "\n",
    "# Question 8\n",
    "1. Groupby Sex and Survived totalling the number of survivors for each sex.\n",
    "2. Create a bar plot of the groupby data for Sex and Survived.\n",
    "3. Create a groupby for Embark and Survived.\n",
    "4. Create a bar plot of the groupby data for Embark and Survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ce0232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c150cce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae56b216",
   "metadata": {},
   "source": [
    "# Separate Features and Target Variables\n",
    "It is now time to separate the Features and the target variables.\n",
    "\n",
    "Use the drop('Target Variable', axis=1) method to drop the target variable.\n",
    "\n",
    "# Question 9\n",
    "1. Using the appropriate dataframe for the training data assign the Target variable to y.\n",
    "2. Using the appropriate dataframe for the training data assign the features to X by dropping the target variable.\n",
    "3. Using the appropriate dataframe for the testing data assign the Target variable to y_test.\n",
    "4. Using the appropriate dataframe for the testing data assign the Target variable to X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3618781e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a535577c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "110d7437",
   "metadata": {},
   "source": [
    "# Create numeric pipeline\n",
    "It is now time to create the numeric pipeline.  Use what you learned in Week 04 to create the numeric pipeline.  This time replace missing values with the mean.\n",
    "\n",
    "- **Pipeline** parameters: https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline\n",
    "- **SimpleImputer**: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer\n",
    "- **Standard Scaler** - https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler\n",
    "\n",
    "<br>\n",
    "\n",
    "# Question 10\n",
    "1. Use the code learned in Week 04 to create a numeric pipeline.\n",
    "2. Include SimpleImputer replacing the missing values with mean(strategry='mean')\n",
    "3. Include a StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82921d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecadb1bd",
   "metadata": {},
   "source": [
    "# Create Categorical pipeline\n",
    "It is now time to create the categorical pipeline.  Use what your learned in Week 04 to create the numeric pipeline.\n",
    "\n",
    "- **make_pipeline** parameters: https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html\n",
    "- **SimpleImputer** parameters: see above\n",
    "- **OneHotEncoder** parameters: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder\n",
    "\n",
    "<br>\n",
    "\n",
    "# Question 11\n",
    "1. Use the code learned in Week 04 to create a categorical pipeline.\n",
    "2. Include SimpleImputer replacing the missing values with most_frequent.\n",
    "3. Include a OneHotEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b9de8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "442d93f9",
   "metadata": {},
   "source": [
    "# Preprocessing Pipeline\n",
    "Create a preprocessing Pipeline to combine the numeric and categorical pipeline.  \n",
    "\n",
    "- **make_column_transformer** parameters:https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_transformer.html#sklearn.compose.make_column_transformer\n",
    "- **make_column_selector** parameters: https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_selector.html#sklearn.compose.make_column_selector\n",
    "\n",
    "\n",
    "# Question 12\n",
    "1. Use what you learned in Week 04 to combine the numeric and categorical pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb57cf74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2645718",
   "metadata": {},
   "source": [
    "# Create model for Logistic Regression\n",
    "The first model you will create is the Logistic Regression model similar to you creating the regression model.  However, this model with include the Cross-Validation within it.\n",
    "\n",
    "- **LogisticRegressionCV** parameters:https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV\n",
    "- **Pipeline** parameters:https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline\n",
    "\n",
    "```\n",
    "log_pipeline = Pipeline([\n",
    "           ('preprocessor', preprocessor),\n",
    "           ('classifier', LogisticRegressionCV(cv=10, max_iter=200, solver='liblinear', random_state=42,                          class_weight='balanced')\n",
    "           ])\n",
    "```\n",
    "\n",
    "# Question 13\n",
    "1. Create a logistic regression with Cross Validation to include in a pipeline for logistic_pipeline.\n",
    "2. The parameters for the LogisticRegressionCV class should be cv=5, max_iter=200, solver='liblinear', random_state=42, class_weight='balanced', and penalty='l2'\n",
    "3. Fit the model using the X and y variables.\n",
    "4. Run the predict model using X and assign it to y_pred.\n",
    "5. Run the predict model using X_test and assign it to y_pred_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370f9a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 13\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8ff28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 13\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f1354d",
   "metadata": {},
   "source": [
    "# Determine the Metrics for Logistic Regression\n",
    "Since the data is not balanced we need more than the accuracy score.  We will compute the precision, recall, f1 score and the confusion matrix.\n",
    "\n",
    "- **accuracy_score** parameters:https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score\n",
    "- **precision_score** parameters: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score\n",
    "- **recall_score parameters**: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score\n",
    "- **f1_score parameters**: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\n",
    "- **confusion_matrix parameters**: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix\n",
    "\n",
    "```\n",
    "m1  = accuracy_score(y, ypred)  # training set\n",
    "m1t = accuracy_score(y_test, ypredtest)\n",
    "print(\"Training accuracy score: \", m1)\n",
    "print(\"Testing accuracy score:\", m1t\n",
    "m2 = precision_score(y, ypred)\n",
    "m3 = recall_score(y, ypred)\n",
    "m4 = f1_score(y, ypred)\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "cmn = confusion_matrix(y, y_pred, normalize='true')\n",
    "print(\"Training Confusion Matrix\\n\", cm)\n",
    "print(\"Training Confusion Matrix normalize \\n\", cmn)\n",
    "```\n",
    "\n",
    "\n",
    "# Question 14\n",
    "1. Compute the accuracy score for the training data set put result in train_a.  ompute the accuracy score for the test data set put result in test_a.  Print both out.\n",
    "2. Compute the precision score for the training and test data sets put in train_p and test_p.  Print both out.\n",
    "3. Compute the recall score for the training and test data sets put in train_r and test_r.  Print both out.\n",
    "4. Compute the f1_score for the training and test data sets sets put in train_f1 and test_f1.  Print both out.\n",
    "5. Compute the confusion matrix without normalize = 'true' and with normalize='true'\n",
    "11. Compute the confustion matrix with normalize = True and print it out for training and testing data sets.  Put the results in train_cmn and test_cmn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98fafca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 14  1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb1f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 14  2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf223ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 14  3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2963fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 14  4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139a3c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 14  5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6c15eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 14  6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f720b1",
   "metadata": {},
   "source": [
    "# Question 15\n",
    "Is the model overfitting the data?   yes or no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be547439",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
