{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "419043bd",
   "metadata": {},
   "source": [
    "# Week 06 - Classification Models KNN\n",
    "The goal of this assignment is to introduce students to classification models, helping them understand how to apply machine learning algorithms to predict categories. Students will work with two datasets and will use a variety of classification models to compare their performance. The assignment will focus on using **K-Nearest Neighbor** in this Jupyter Notebook.\n",
    "<br><br>\n",
    "The libraries that you will use are listed in the code cell below. Please run the code cell. See the Getting Started module in the Canvas Classroom to see the parameter options available to each class and method used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca7a6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, balanced_accuracy_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730cc29c",
   "metadata": {},
   "source": [
    "# Reading in the Data set\n",
    " You will use the Wine Quality data set to predict the wine quality. This data set was originally used tin regression models since the quality was numeric.  We will change the output to Low=0, Medium=1, and High=2. The code beloow reads data into the a dataframe from a dataset located on the Internet.\n",
    " \n",
    " \n",
    "- apply() parameters: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html#pandas.DataFrame.apply\n",
    "- lambda definition: https://www.geeksforgeeks.org/python-lambda-anonymous-functions-filter-map-reduce/#\n",
    "- lambda with dataframes: \n",
    "\n",
    "\n",
    "```\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "df = pd.read_csv(url, sep=';')  # CSV uses \";\" as a separator\n",
    "\n",
    "# if the quality code is less than or equal to 5 change to 0.\n",
    "# if the quality code is 6 change to 1.\n",
    "# If greater than 6 change quality code to 2.\n",
    "df['quality'] = df['quality'].apply(lambda x: 0 if x <= 5 else (1 if x == 6 else 2))\n",
    "```\n",
    "To see the parameters of pd.read_csv click this url: https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "\n",
    "# Question 1\n",
    "1. Read the wine data set into a dataframe variable called wine.\n",
    "2. Change the quality column using the lambda function with the apply() method to create three classes for target variable (see code above).\n",
    "2. Display the first 5 records in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d5b7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe42b009",
   "metadata": {},
   "source": [
    "# Data Structure and Summary Statistics\n",
    "Create a data structure list and also the summary statistics using the info(), describe().T, describe(include=['object']).T methods.\n",
    "\n",
    "- info() parameters: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html#pandas.DataFrame.info\n",
    "- describe() parameters: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html#pandas.DataFrame.describe\n",
    "\n",
    "\n",
    "\n",
    "# Question 2\n",
    "1. Use the appropriate dataframe variable and list the data structure using info() method.\n",
    "2. Use the appropriate dataframe variable and list the data structure using describe().T for the numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbc504f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2 - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44b8695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2 - 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc2e9f7",
   "metadata": {},
   "source": [
    "# Determine balanced data\n",
    "Is the data balanced?  Is the target variable equal in each output value?  \n",
    "\n",
    "- df['column'].value_counts()\n",
    "- value_counts method parameters: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html#pandas.DataFrame.value_counts \n",
    "\n",
    "```\n",
    "df['column'].value_counts(normalize=True)*100\n",
    "```\n",
    "\n",
    "# Question 3\n",
    "1. Use the value_counts() method to determine if the target variable, quality has equal values.\n",
    "2. Use the parameter normalize=True to determine the percentage in each quality number.  You can multiple by 100 to get the percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c03930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3 - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b37a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3 - 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e441ae",
   "metadata": {},
   "source": [
    "# Splitting the dataset\n",
    "It is time to split the dataset into training and testing data sets.  Since the Survived column is not equal we will use a stratified random sample based on the Survived column.\n",
    "\n",
    "- train_test_split parameters: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "- train, test = train_test_split(df, test_size=0.2, random_state=33, stratify=df['target column'])\n",
    "\n",
    "# Question 5\n",
    "1. Split the data into train and test dataframes using the train_test_split function.\n",
    "2. Split the data 70% in training and 30% in testing.\n",
    "3. Use the random_state = 42. (seed for random number generator)\n",
    "4. Stratified the data by the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc33dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d0dff3",
   "metadata": {},
   "source": [
    "# View the percentage in training and test set\n",
    "We stratified the sample based on the target variable.  We can see the results of the target variables in the test and training set by using the value_counts(normalize=True).\n",
    "\n",
    "```\n",
    "df['column'].value_counts(normalize=True) # to get percentage in each number in Survived for test set\n",
    "df_t['column'].value_counts(normalize=True) # to get percentage in each number in Survived for test set\n",
    "```\n",
    "# Question 6\n",
    "1. Determine the percentage for the target variable for the entire data set.\n",
    "2. Determine the percentage for the target variable in the training data set.\n",
    "3. Determine the percentage for the target variable in the testing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f571617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 6 - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5642ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 6 - 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03feef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 6 - 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46ec587",
   "metadata": {},
   "source": [
    "# Correlation of training data set\n",
    "Create a correlation matrix of the training data set using the corr() method\n",
    "- the corr() parameters is at this url: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html#pandas.DataFrame.corr\n",
    "\n",
    "```\n",
    "df_t.corr(numeric_only=True)\n",
    "```\n",
    "\n",
    "# Question 7\n",
    "1. Using the corr() method and numeric_only=True as the parameter along with the appropriate dataframe to fine the correlation matrix of the training data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61f63d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1c567b",
   "metadata": {},
   "source": [
    "# Data Visualization\n",
    "Create a correlation heatmap to easily view the correlation coefficient matrix.  If the correlation between the features is greater than 0.75 or less than -0.75 you should drop one of the variables.\n",
    "\n",
    "\n",
    "- sns.heatmap parameters: https://seaborn.pydata.org/generated/seaborn.heatmap.html\n",
    "- plt.figure( parameters: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.figure.html\n",
    "- plt.title( parameters: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.title.html#matplotlib.pyplot.title\n",
    "- plt.show( parameters: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.show.html#matplotlib.pyplot.show\n",
    "\n",
    "<br>\n",
    "\n",
    "```\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "# Question 8\n",
    "1. Create a heatmap of the correlation coefficient of train data set by applying the appropriate dataframe to the code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ce0232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae56b216",
   "metadata": {},
   "source": [
    "# Separate Features and Target Variables\n",
    "It is now time to separate the Features and the target variables.\n",
    "\n",
    "Use the drop('Target Variable', axis=1) method to drop the target variable.\n",
    "\n",
    "# Question 9\n",
    "1. Using the appropriate dataframe for the training data assign the Target variable to y.  Then using the appropriate dataframe for the training data assign the features to X by dropping the target variable.\n",
    "2. Using the appropriate dataframe for the testing data assign the Target variable to y_test.  Then using the appropriate dataframe for the testing data assign the Target variable to X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019ce735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 9 - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851240f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 9 - 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2645718",
   "metadata": {},
   "source": [
    "# Create model K-Nearest Neighbor\n",
    "The first model you will create is the K-Nearest Neighbor model where the number of neighbors is set by the parameter n_neighbors.  Since the data set has no missing values we can eliminate the imputer.  Since there is no string column values so we can eliminate the category pipeline.  So only StandardScaler and KNeighborsClassifier is needed.\n",
    "\n",
    "- **KNeighborsClassifer** parameters:https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "- **StandardScaler** parameters: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler\n",
    "- **StratifiedKFolder** parameters: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold\n",
    "\n",
    "```\n",
    "sk = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  # deals with imbalanced data\n",
    "\n",
    "cv_score = cross_val_score(knnpipeline, X, y, cv=sk, scoring='accuracy')\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "# Question 13\n",
    "1. Using what you learned in the last two homework assignments create a pipeline for the K-Nearest Neighbor called knn_pipeline using Pipeline with StandardScaler and KNeighborsClassifier with n_neighbors=5.\n",
    "2. Fit the knn_pipeline with the X and y variables for training data set.\n",
    "3. Predict the knn_pipeline with X and assign to variable y_pred\n",
    "4. Using the code above create StratifiedKFold to deal with imbalance data.  Assign to variable skf.\n",
    "5. Using the code above to compute the cross validation for the training data set.  Assign it to variable train_scores\n",
    "6. Predict the knn_pipeline with X_test and assign to variable y_pred_test. \n",
    "7. Using the code above to compute the cross validation for the test data set (X_test, y_test).  Assign it to variable test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370f9a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 13  - 1) and 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8ff28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 13  - 3) and 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f848ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 13 -  5)  thru 7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f1354d",
   "metadata": {},
   "source": [
    "# Determine the Metrics for KNN\n",
    "Since the data is not balanced we need more than the accuracy score.  We will compute the precision, recall, f1 score and the confusion matrix.\n",
    "\n",
    "- **balanced_accuracy_score** parameters:https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html#sklearn.metrics.balanced_accuracy_score\n",
    "- **precision_score** parameters: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score\n",
    "- **recall_score parameters**: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score\n",
    "- **f1_score parameters**: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\n",
    "- **confusion_matrix parameters**: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix\n",
    "\n",
    "```\n",
    "m1  = balanced_accuracy_score(y, ypred)  # training set\n",
    "m1t = balanced_accuracy_score(y_test, ypredtest)\n",
    "print(\"Training accuracy score: \", m1)\n",
    "print(\"Testing accuracy score:\", m1t\n",
    "m2 = precision_score(y, ypred, average = 'weighted')\n",
    "m3 = recall_score(y, ypred)\n",
    "m4 = f1_score(y, ypred)\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "cmn = confusion_matrix(y, y_pred, normalize='true')\n",
    "print(\"Training Confusion Matrix\\n\", cm)\n",
    "print(\"Training Confusion Matrix normalize \\n\", cmn)\n",
    "```\n",
    "\n",
    "\n",
    "# Question 14\n",
    "1. Print out accuracy score calculated in Question 13 for training and test data set.\n",
    "2. Compute the precision score for the training and test data sets put in train_p and test_p.  Print both out.\n",
    "3. Compute the recall score for the training and test data sets put in train_r and test_r.  Print both out.\n",
    "4. Compute the f1_score for the training and test data sets sets put in train_f1 and test_f1.  Print both out.\n",
    "5. Compute the confusion matrix without normalize = 'true' and with normalize='true'\n",
    "6. Compute the confustion matrix with normalize = True and print it out for training and testing data sets.  Put the results in train_cmn and test_cmn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98fafca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 14  1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb1f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 14  2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf223ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 14  3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2963fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 14  4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139a3c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 14  5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6c15eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 14  6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f720b1",
   "metadata": {},
   "source": [
    "# Question 15\n",
    "Is this a good model, based on accuracy score? why? Is it overfitting?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be547439",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=''\n",
    "why=''\n",
    "overfitting=''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
